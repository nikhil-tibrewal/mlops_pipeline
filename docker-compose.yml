version: "3.8"

services:
  # Runs training + DAG orchestration
  airflow-webserver:
    build: ./airflow
    container_name: airflow-webserver
    restart: always
    depends_on:
      - airflow-scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - airflow_db:/opt/airflow
      - mlruns:/mlflow/mlruns
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/models:/opt/airflow/models
    ports:
      - "8080:8080" # To expose airflow UI
    command: webserver

  airflow-scheduler:
    build: ./airflow
    container_name: airflow-scheduler
    restart: always
    environment:
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
    volumes:
      - airflow_db:/opt/airflow
      - mlruns:/mlflow/mlruns
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/models:/opt/airflow/models
    command: scheduler

  # Tracking UI, experiment logs
  mlflow-server:
    build: ./mlflow
    container_name: mlflow-server
    restart: always
    volumes:
      - mlruns:/mlflow/mlruns
    ports:
      - "5000:5000"
    command: >
      mlflow server
      --backend-store-uri /mlflow/mlruns
      --default-artifact-root /mlflow/mlruns
      --host 0.0.0.0
      --port 5000

  # Serves trained model as REST API
  model-server:
    build: ./mlflow
    container_name: model-server
    restart: always
    ports:
      - "5001:5001"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
    volumes:
      - mlruns:/mlflow/mlruns
    command: >
      mlflow models serve
      -m runs:/16e97ba25e664c24b842ca3e09ac79ed/model
      --no-conda
      --host 0.0.0.0
      --port 5001
volumes:
  airflow_db:
  mlruns: