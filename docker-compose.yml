version: "3.8"

services:
  # Runs training + DAG orchestration
  airflow-webserver:
    build: ./airflow
    container_name: airflow-webserver
    restart: always
    depends_on:
      - volume-init
      - airflow-scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - airflow_db:/opt/airflow
      - mlruns:/mlflow/mlruns
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/models:/opt/airflow/models
    ports:
      - "8080:8080" # To expose airflow UI
    command: webserver

  airflow-scheduler:
    build: ./airflow
    container_name: airflow-scheduler
    restart: always
    environment:
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
    volumes:
      - airflow_db:/opt/airflow
      - mlruns:/mlflow/mlruns
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/models:/opt/airflow/models
    command: scheduler

  # Tracking UI, experiment logs
  mlflow-server:
    build: ./mlflow
    container_name: mlflow-server
    restart: always
    user: "50000:0" # Run as airflow user
    volumes:
      - mlruns:/mlflow/mlruns
    ports:
      - "5000:5000"
    command: >
      mlflow server
      --backend-store-uri /mlflow/mlruns
      --default-artifact-root /mlflow/mlruns
      --host 0.0.0.0
      --port 5000

  # Serves trained model as REST API
  model-server:
    build: ./mlflow
    container_name: model-server
    restart: always
    ports:
      - "5001:5001"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
    volumes:
      - mlruns:/mlflow/mlruns
    command: >
      mlflow models serve
      -m runs:/${LATEST_MODEL_RUN_ID}/model
      --no-conda
      --host 0.0.0.0
      --port 5001

  # A short-lived init service that waits for the mlruns_vol volume to be mounted, creates any needed directories and sets ownership to airflow.
  volume-init:
    image: busybox
    volumes:
      - mlruns:/mlflow/mlruns
    entrypoint: ["/bin/sh", "-c"]
    command: ["mkdir -p /mlflow/mlruns && touch /mlflow/mlruns/.init && chown -R 50000:0 /mlflow/mlruns"]

volumes:
  airflow_db:
  mlruns: